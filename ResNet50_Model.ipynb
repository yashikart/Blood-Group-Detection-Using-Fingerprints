{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZmrJLHpAKasJNbqxkNg9B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashikart/Blood-Group-Detection-Using-Fingerprints/blob/main/ResNet50_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlI9cKU_4qVu",
        "outputId": "3ef38199-28b6-4249-ea95-cbd3e470b7ca"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Found 6800 images belonging to 8 classes.\n",
            "Found 320 images belonging to 8 classes.\n",
            "\n",
            "Balanced Class Distribution:\n",
            "ðŸ©¸ A+: 850 samples\n",
            "ðŸ©¸ A-: 850 samples\n",
            "ðŸ©¸ AB+: 850 samples\n",
            "ðŸ©¸ AB-: 850 samples\n",
            "ðŸ©¸ B+: 850 samples\n",
            "ðŸ©¸ B-: 850 samples\n",
            "ðŸ©¸ O+: 850 samples\n",
            "ðŸ©¸ O-: 850 samples\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "\n",
            "ðŸš€ Training ResNet50...\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m213/213\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5266s\u001b[0m 24s/step - accuracy: 0.5134 - loss: 1.2600 - val_accuracy: 0.1156 - val_loss: 2.6461\n",
            "Epoch 2/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5054s\u001b[0m 24s/step - accuracy: 0.7156 - loss: 0.6461 - val_accuracy: 0.1969 - val_loss: 2.2435\n",
            "Epoch 3/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5037s\u001b[0m 24s/step - accuracy: 0.7709 - loss: 0.5143 - val_accuracy: 0.3063 - val_loss: 1.8617\n",
            "Epoch 4/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5048s\u001b[0m 24s/step - accuracy: 0.7938 - loss: 0.4527 - val_accuracy: 0.4719 - val_loss: 1.6285\n",
            "Epoch 5/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5060s\u001b[0m 24s/step - accuracy: 0.8183 - loss: 0.3908 - val_accuracy: 0.7219 - val_loss: 0.7306\n",
            "Epoch 6/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5118s\u001b[0m 24s/step - accuracy: 0.8349 - loss: 0.3564 - val_accuracy: 0.6938 - val_loss: 0.8407\n",
            "Epoch 7/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5026s\u001b[0m 24s/step - accuracy: 0.8456 - loss: 0.3308 - val_accuracy: 0.7250 - val_loss: 0.7412\n",
            "Epoch 8/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4985s\u001b[0m 23s/step - accuracy: 0.8525 - loss: 0.3131 - val_accuracy: 0.7531 - val_loss: 0.6388\n",
            "Epoch 9/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4928s\u001b[0m 23s/step - accuracy: 0.8467 - loss: 0.3011 - val_accuracy: 0.7188 - val_loss: 0.8827\n",
            "Epoch 10/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4923s\u001b[0m 23s/step - accuracy: 0.8477 - loss: 0.2998 - val_accuracy: 0.7156 - val_loss: 0.7387\n",
            "Epoch 11/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4955s\u001b[0m 23s/step - accuracy: 0.8626 - loss: 0.2729 - val_accuracy: 0.7250 - val_loss: 0.6513\n",
            "Epoch 12/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5052s\u001b[0m 24s/step - accuracy: 0.8600 - loss: 0.2652 - val_accuracy: 0.6781 - val_loss: 0.8707\n",
            "Epoch 13/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5035s\u001b[0m 24s/step - accuracy: 0.8538 - loss: 0.2927 - val_accuracy: 0.7281 - val_loss: 0.6505\n",
            "âœ… ResNet50 saved to /content/drive/MyDrive/Blood Group Detection/Models_4/ResNet50.keras\n",
            "ðŸ“Š Final Accuracy for ResNet50 -> Train: 85.40%, Validation: 72.81%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.applications import EfficientNetB3, EfficientNetB0, ResNet50, Xception, ConvNeXtBase, DenseNet121\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from shutil import copyfile, rmtree\n",
        "\n",
        "# âœ… Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# âœ… Define dataset paths\n",
        "original_train_dir = \"/content/drive/MyDrive/Blood Group Detection/Gabor filter_1/Train\"\n",
        "test_data_dir = \"/content/drive/MyDrive/Blood Group Detection/Gabor filter_1/Test\"\n",
        "\n",
        "# âœ… Temporary directory for balanced dataset\n",
        "balanced_train_dir = \"/content/balanced_train\"\n",
        "if os.path.exists(balanced_train_dir):\n",
        "    rmtree(balanced_train_dir)\n",
        "os.makedirs(balanced_train_dir)\n",
        "\n",
        "# âœ… Ensure 850 images per class\n",
        "min_train_samples = 850\n",
        "\n",
        "for class_name in os.listdir(original_train_dir):\n",
        "    class_path = os.path.join(original_train_dir, class_name)\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue\n",
        "\n",
        "    images = os.listdir(class_path)\n",
        "    os.makedirs(os.path.join(balanced_train_dir, class_name), exist_ok=True)\n",
        "\n",
        "    if len(images) >= min_train_samples:\n",
        "        selected_images = random.sample(images, min_train_samples)\n",
        "    else:\n",
        "        selected_images = images  # Use all available images\n",
        "\n",
        "    # Copy selected images to balanced directory\n",
        "    for img in selected_images:\n",
        "        src = os.path.join(class_path, img)\n",
        "        dst = os.path.join(balanced_train_dir, class_name, img)\n",
        "        copyfile(src, dst)\n",
        "\n",
        "# âœ… Set parameters\n",
        "img_width, img_height = 224, 224\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "\n",
        "# âœ… Define Data Generators (No Augmentation)\n",
        "data_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    balanced_train_dir, target_size=(img_width, img_height),\n",
        "    batch_size=batch_size, class_mode='categorical'\n",
        ")\n",
        "test_generator = data_gen.flow_from_directory(\n",
        "    test_data_dir, target_size=(img_width, img_height),\n",
        "    batch_size=batch_size, class_mode='categorical', shuffle=False\n",
        ")\n",
        "\n",
        "num_classes = len(train_generator.class_indices)\n",
        "\n",
        "# âœ… Check dataset balance\n",
        "print(\"\\nBalanced Class Distribution:\")\n",
        "for class_name, count in train_generator.class_indices.items():\n",
        "    print(f\"ðŸ©¸ {class_name}: {min_train_samples} samples\")\n",
        "\n",
        "# âœ… Define Model Architectures\n",
        "def create_model(base_model_func):\n",
        "    base_model = base_model_func(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "    x = GlobalAveragePooling2D()(base_model.output)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    output = Dense(num_classes, activation='softmax')(x)\n",
        "    return Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# âœ… Instantiate models (Including DenseNet121)\n",
        "models = {\n",
        "    \"ResNet50\": create_model(ResNet50)\n",
        "}\n",
        "\n",
        "# âœ… Train and save models\n",
        "for model_name, model in models.items():\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    print(f\"\\nðŸš€ Training {model_name}...\")\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    history = model.fit(train_generator, epochs=epochs, validation_data=test_generator, callbacks=[early_stopping])\n",
        "\n",
        "    # âœ… Save the model\n",
        "    model_path = f\"/content/drive/MyDrive/Blood Group Detection/Models_4/{model_name}.keras\"\n",
        "    model.save(model_path)\n",
        "    print(f\"âœ… {model_name} saved to {model_path}\")\n",
        "\n",
        "    # âœ… Print final training accuracy\n",
        "    train_acc = history.history['accuracy'][-1] * 100\n",
        "    val_acc = history.history['val_accuracy'][-1] * 100\n",
        "    print(f\"ðŸ“Š Final Accuracy for {model_name} -> Train: {train_acc:.2f}%, Validation: {val_acc:.2f}%\")\n"
      ]
    }
  ]
}